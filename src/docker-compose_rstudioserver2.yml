version: "3"

services:

  namenode:
    image: harryyhzhang/hadoop2.7hive2.3.2spark2.0.2r3.4
    ports:
      - "50070:50070"
    hostname: testbed-master
    container_name: testbed-master
    entrypoint:  sh -c  "service ssh start && /usr/local/hadoop/spark-services.sh && hadoop fs -mkdir /user/rstudio && hadoop fs -chmod 777 /user/rstudio && /usr/sbin/rstudio-server start && bash " 
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    tty: true
    stdin_open: true
    networks:
      webnet:
        ipv4_address: 192.168.33.2

  datanode1:
    image: harryyhzhang/hadoop2.7hive2.3.2spark2.0.2r3.4
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    hostname: testbed-slave-1
    container_name: testbed-slave-1
    tty: true
    stdin_open: true
    networks:
      webnet:
        ipv4_address: 192.168.33.3


networks:
 webnet:
   external:
     name: shared_nw

volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  hadoop_datanode3:
  hadoop_historyserver: